# OGIex
![Shell Script](https://img.shields.io/badge/Shell%20Script-2c2c2c?logo=gnu-bash&logoColor=white&style=flat-square)
![tested](https://img.shields.io/badge/Tested_on-Ubuntu-red?style=flat-square)
![License](https://img.shields.io/github/license/Obarads/OGIex?color=green&style=flat-square)

OGIex are scripts from building a docker image to running a demo by two commands.

## How to use
1. Select a script dir in the `environments` dir.
2. Check a `README.md` written commands to run scripts in the folder.

## Script dir list

| Dirname | Code | Paper |
| --- | --- | --- |
| [3DSSD](./environments/3DSSD) | [Official](https://github.com/dvlab-research/3DSSD) | [3DSSD: Point-based 3D Single Stage Object Detector](https://arxiv.org/abs/2002.10187) |
| [CoDeF](./environments/CoDeF) | [Official](https://github.com/qiuyu96/CoDeF) | [CoDeF: Content Deformation Fields for Temporally Consistent Video Processing](https://arxiv.org/abs/2308.07926) |
| [KPConv](./environments/KPConv) | [Official](https://github.com/HuguesTHOMAS/KPConv) | [KPConv: Flexible and Deformable Convolution for Point Clouds](https://arxiv.org/abs/1904.08889) |
| [MultiDiffusion](./environments/MultiDiffusion) | [Official](https://github.com/omerbt/MultiDiffusion) | [MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation](https://arxiv.org/abs/2302.08113) |
| [Point-Bind_Point-LLM](./environments/Point-Bind_Point-LLM) | [Official](https://github.com/ZiyuGuo99/Point-Bind_Point-LLM) | [Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following](https://arxiv.org/abs/2309.00615) |
| [PointNeXt](./environments/PointNeXt) | [Official](https://github.com/guochengqian/PointNeXt) | [PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies](https://arxiv.org/abs/2206.04670) |
| [RandLA-Net](./environments/RandLA-Net) | [Official](https://github.com/QingyongHu/RandLA-Net) | [RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds](https://arxiv.org/abs/1911.11236) |
| [Text2Tex](./environments/Text2Tex) | [Official](https://github.com/daveredrum/Text2Tex) | [Text2Tex: Text-driven Texture Synthesis via Diffusion Models](https://arxiv.org/abs/2303.11396) |
| [cc3d](./environments/cc3d) | [Official](https://github.com/sherwinbahmani/cc3d) | [CC3D: Layout-Conditioned Generation of Compositional 3D Scenes](https://arxiv.org/abs/2303.12074) |
| [dreamfields](./environments/dreamfields) | [Official](https://github.com/google-research/google-research/tree/master/dreamfields) | [Zero-Shot Text-Guided Object Generation with Dream Fields](https://arxiv.org/abs/2112.01455) |
| [dreamgaussian](./environments/dreamgaussian) | [Official](https://github.com/dreamgaussian/dreamgaussian) | [DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation](https://arxiv.org/abs/2309.16653) |
| [gaussian-splatting](./environments/gaussian-splatting) | [Official](https://github.com/graphdeco-inria/gaussian-splatting) | [3D Gaussian Splatting for Real-Time Radiance Field Rendering](https://arxiv.org/abs/2308.04079) |
| [panoptic-lifting](./environments/panoptic-lifting) | [Official](https://github.com/nihalsid/panoptic-lifting) | [Panoptic Lifting for 3D Scene Understanding](https://arxiv.org/abs/2212.09802) |
| [point-e](./environments/point-e) | [Official](https://github.com/openai/point-e) | [Point·E: A System for Generating 3D Point Clouds from Complex Prompts](https://arxiv.org/abs/2206.04670) |
| [realfusion](./environments/realfusion) | [Official](https://github.com/lukemelas/realfusion) | [RealFusion: 360° Reconstruction of Any Object from a Single Image](https://arxiv.org/abs/2302.10663) |
| [retnet](./environments/retnet) | [Official](https://github.com/microsoft/unilm/tree/master/retnet) | [Retentive Network: A Successor to Transformer for Large Language Models](https://arxiv.org/abs/2307.08621) |
| [shap-e](./environments/shap-e) | [Official](https://github.com/openai/shap-e) | [Shap-E: Generating Conditional 3D Implicit Functions](https://arxiv.org/abs/2305.02463) |
| [stable-diffusion](./environments/stable-diffusion) | [Official](https://github.com/CompVis/stable-diffusion) | [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752) |
| [stable-dreamfusion](./environments/stable-dreamfusion) | [Unofficial](https://github.com/ashawkey/stable-dreamfusion) | [DreamFusion: Text-to-3D using 2D Diffusion](https://arxiv.org/abs/2209.14988) |
| [text2room](./environments/text2room) | [Official](https://github.com/lukasHoel/text2room) | [Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models](https://arxiv.org/abs/2303.11989) |
| [torchscale](./environments/torchscale) | [Official](https://github.com/microsoft/torchscale) | [TorchScale: Transformers at Scale](https://arxiv.org/abs/2303.11396) |
| [torchsparse](./environments/torchsparse) | [Official](https://github.com/mit-han-lab/torchsparse) | [TorchSparse++: Efficient Point Cloud Engine](https://openaccess.thecvf.com/content/CVPR2023W/WAD/html/Tang_TorchSparse_Efficient_Point_Cloud_Engine_CVPRW_2023_paper.html) |
